{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\PROJECT\\sites\\us_kon\\us_kon.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "df.replace(-9990, np.nan, inplace=True)\n",
    "wet_year = 2008\n",
    "drought_year = 2012\n",
    "normal_year = 2015\n",
    "year_colors = {\n",
    "    wet_year: 'darkblue',\n",
    "    drought_year: 'darkred',\n",
    "    normal_year: 'darkgreen'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ET CALC\n",
    "latent_heat_of_vaporization = 2.45*10**6  # MJ/kg\n",
    "df['ET_eddy_cov'] = df['LE']*1000 / latent_heat_of_vaporization\n",
    "df.to_csv(file_path , index=False)\n",
    "print(\"New column named ET_eddy_cov is created in the new CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:\\\\PROJECT\\\\sites\\\\DBF\\\\MISSOURI\\\\MISSOURI.csv\",  parse_dates=['TIMESTAMP_START'])\n",
    "df['TIMESTAMP_START'] = pd.to_datetime(df['TIMESTAMP_START'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "df['Year'] = df['TIMESTAMP_START'].dt.year\n",
    "df['Month'] = df['TIMESTAMP_START'].dt.month\n",
    "df['Hour'] = df['TIMESTAMP_START'].dt.hour\n",
    "df['Minute'] = df['TIMESTAMP_START'].dt.minute\n",
    "time_slots = [(0, 0), (0, 30), (1, 0), (1, 30), (2, 0), (2, 30), (3, 0), (3, 30), (4, 0), (4, 30),\n",
    "               (5, 0), (5, 30), (6, 0), (6, 30), (7, 0), (7, 30), (8, 0), (8, 30), (9, 0), (9, 30),\n",
    "               (10, 0), (10, 30), (11, 0), (11, 30), (12, 0), (12, 30), (13, 0), (13, 30), (14, 0), (14, 30),\n",
    "               (15, 0), (15, 30), (16, 0), (16, 30), (17, 0), (17, 30), (18, 0), (18, 30), (19, 0), (19, 30),\n",
    "               (20, 0), (20, 30), (21, 0), (21, 30), (22, 0), (22, 30), (23, 0), (23, 30)]\n",
    "\n",
    "\n",
    "df_filtered = df[df[['Hour', 'Minute']].apply(tuple, axis=1).isin(time_slots)]\n",
    "\n",
    "average_temp = df_filtered.groupby(['Year', 'Month','Hour', 'Minute'])['TEMP'].mean().reset_index()\n",
    "average_VPD = df_filtered.groupby(['Year', 'Month','Hour', 'Minute'])['VPD'].mean().reset_index()\n",
    "#average_Rn = df_filtered.groupby(['Year', 'Month','Hour', 'Minute'])['Net_Radiation'].mean().reset_index()\n",
    "average_ET = df_filtered.groupby(['Year', 'Month','Hour', 'Minute'])['ET_eddy_cov'].mean().reset_index()\n",
    "average_GPP_NT = df_filtered.groupby(['Year', 'Month','Hour', 'Minute'])['GPP_NT_VUT_REF'].mean().reset_index()\n",
    "average_GPP_DT = df_filtered.groupby(['Year', 'Month','Hour', 'Minute'])['GPP_DT_VUT_REF'].mean().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "average_temp.columns = ['Year', 'Month','Hour', 'Minute', 'Average_Temperature']\n",
    "average_VPD.columns = ['Year', 'Month','Hour', 'Minute', 'Average_VPD']\n",
    "#average_Rn.columns = ['Year', 'Month','Hour', 'Minute', 'Average_net_radiation']\n",
    "average_ET.columns = ['Year', 'Month','Hour', 'Minute', 'Average_ET']\n",
    "average_GPP_NT.columns = ['Year', 'Month','Hour', 'Minute', 'Average_GPP_NT']\n",
    "average_GPP_DT.columns = ['Year', 'Month','Hour', 'Minute', 'Average_GPP_DT']\n",
    "\n",
    "average_ET = average_ET[average_ET['Average_ET'] >= 0]\n",
    "average_GPP_NT = average_GPP_NT[average_GPP_NT['Average_GPP_NT'] >= 0]\n",
    "average_GPP_DT = average_GPP_DT[average_GPP_DT['Average_GPP_DT'] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## YEARLY PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "merged_data = pd.merge(average_GPP_DT, average_ET, on=['Year','Month','Hour','Minute'])\n",
    "variables=[('Average_GPP_DT','Average_ET','GPP vs ET')]\n",
    "month_names=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "years=merged_data['Year'].unique()\n",
    "for year in years:\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.suptitle(f'Year: {year}',fontsize=16)\n",
    "    for month in range(1,13):\n",
    "        ax=plt.subplot(3,4,month)\n",
    "        monthly_data=merged_data[(merged_data['Year']==year)&(merged_data['Month']==month)]\n",
    "        sorted_data=monthly_data.sort_values(by=['Hour','Minute'])\n",
    "        ax.scatter(sorted_data['Average_GPP_DT'],sorted_data['Average_ET'],alpha=0.5,label='GPP vs ET',edgecolor='none')\n",
    "        for j in range(len(sorted_data)-1):\n",
    "            x_start=sorted_data.iloc[j]['Average_GPP_DT']\n",
    "            y_start=sorted_data.iloc[j]['Average_ET']\n",
    "            x_end=sorted_data.iloc[j+1]['Average_GPP_DT']\n",
    "            y_end=sorted_data.iloc[j+1]['Average_ET']\n",
    "            ax.annotate('',xy=(x_end,y_end),xytext=(x_start,y_start),arrowprops=dict(arrowstyle='->',color='grey',lw=1.0))\n",
    "        ax.set_title(f'{month_names[month-1]}')\n",
    "        ax.set_xlabel('Average_GPP_DT')\n",
    "        ax.set_ylabel('Average_ET')\n",
    "    plt.tight_layout(rect=[0,0,1,0.96])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MONTHLY PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "merged_data=pd.merge(average_GPP_DT,average_ET,on=['Year','Month','Hour','Minute'])\n",
    "variables=[('Average_GPP_DT','Average_ET','GPP vs ET')]\n",
    "month_names=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "years=merged_data['Year'].unique()\n",
    "for month in range(1,13):\n",
    "    plt.figure(figsize=(15,10))\n",
    "    rows=(len(years)+3)//4\n",
    "    cols=4\n",
    "    for i,year in enumerate(years):\n",
    "        ax=plt.subplot(rows,cols,i+1)\n",
    "        monthly_data=merged_data[(merged_data['Year']==year)&(merged_data['Month']==month)]\n",
    "        sorted_data=monthly_data.sort_values(by=['Hour','Minute'])\n",
    "        ax.scatter(sorted_data['Average_GPP_DT'],sorted_data['Average_ET'],alpha=0.5,label=f'Year {year}',edgecolor='none')\n",
    "        for j in range(len(sorted_data)-1):\n",
    "            x_start=sorted_data.iloc[j]['Average_GPP_DT']\n",
    "            y_start=sorted_data.iloc[j]['Average_ET']\n",
    "            x_end=sorted_data.iloc[j+1]['Average_GPP_DT']\n",
    "            y_end=sorted_data.iloc[j+1]['Average_ET']\n",
    "            ax.annotate('',xy=(x_end,y_end),xytext=(x_start,y_start),arrowprops=dict(arrowstyle='->',color='grey',lw=1.0))\n",
    "        ax.set_title(f'{month_names[month-1]} - {year}')\n",
    "        ax.set_xlabel('Average_GPP_DT')\n",
    "        ax.set_ylabel('Average_ET')\n",
    "    plt.tight_layout(rect=[0,0,1,0.96])\n",
    "    plt.suptitle(f'GPP vs ET for {month_names[month-1]}',fontsize=16)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DROUGHT \n",
    "Identify and enter the wet yr(darkblue), drought yr(dark red) and normal yr(dark green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = merged_data[merged_data['Year'].isin([wet_year, drought_year, normal_year])]\n",
    "merged_data = merged_data[merged_data['Month'].between(4, 9)]\n",
    "month_names = ['Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep']\n",
    "year_colors = {wet_year: 'blue', drought_year: 'red', normal_year: 'green'}\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Normalized GPP DT vs Normalized ET (April to September)', fontsize=20)\n",
    "for i, month in enumerate(range(4, 10)):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    monthly_data = merged_data[merged_data['Month'] == month]\n",
    "    GPP_max = monthly_data['Average_GPP_DT'].max()\n",
    "    ET_max = monthly_data['Average_ET'].max()\n",
    "    monthly_data['Normalized_GPP'] = monthly_data['Average_GPP_DT'] / GPP_max\n",
    "    monthly_data['Normalized_ET'] = monthly_data['Average_ET'] / ET_max\n",
    "    for year, color in year_colors.items():\n",
    "        year_data = monthly_data[monthly_data['Year'] == year]\n",
    "        sorted_data = year_data.sort_values(by=['Hour', 'Minute'])\n",
    "        ax.scatter(sorted_data['Normalized_ET'], sorted_data['Normalized_GPP'], alpha=0.5, label=str(year), edgecolor='none', color=color)\n",
    "        for j in range(len(sorted_data) - 1):\n",
    "            x_start = sorted_data.iloc[j]['Normalized_ET']\n",
    "            y_start = sorted_data.iloc[j]['Normalized_GPP']\n",
    "            x_end = sorted_data.iloc[j + 1]['Normalized_ET']\n",
    "            y_end = sorted_data.iloc[j + 1]['Normalized_GPP']\n",
    "            ax.annotate('', xy=(x_end, y_end), xytext=(x_start, y_start), arrowprops=dict(arrowstyle='->', color='grey', lw=1.5))\n",
    "    ax.set_title(month_names[i])\n",
    "    ax.set_xlabel('ET/ET max', fontsize=16)\n",
    "    ax.set_ylabel('GPP/GPPmax', fontsize=16)\n",
    "    ax.legend(title='Year')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data=merged_data[merged_data['Year'].isin([wet_year,drought_year,normal_year])]\n",
    "seasons={'Spring':[3,4,5],'Summer':[6,7,8],'Fall':[9,10,11]}\n",
    "season_colors={'Spring':'green','Summer':'orange','Fall':'brown'}\n",
    "year_colors={wet_year:'blue',drought_year:'red',normal_year:'green'}\n",
    "areas={'Spring':{},'Summer':{},'Fall':{}}\n",
    "fig,axes=plt.subplots(1,3,figsize=(24,8))\n",
    "fig.suptitle('Normalized GPP DT vs Normalized ET (Seasons)',fontsize=20)\n",
    "for i,(season,months) in enumerate(seasons.items()):\n",
    "    ax=axes[i]\n",
    "    season_data=merged_data[merged_data['Month'].isin(months)]\n",
    "    GPP_max=season_data['Average_GPP_DT'].max()\n",
    "    ET_max=season_data['Average_ET'].max()\n",
    "    season_data['Normalized_GPP']=season_data['Average_GPP_DT']/GPP_max\n",
    "    season_data['Normalized_ET']=season_data['Average_ET']/ET_max\n",
    "    for year,color in year_colors.items():\n",
    "        year_data=season_data[season_data['Year']==year]\n",
    "        avg_data=year_data.groupby(['Hour','Minute']).mean().reset_index()\n",
    "        avg_data=avg_data.sort_values(by=['Hour','Minute'])\n",
    "        ax.plot(avg_data['Normalized_GPP'],avg_data['Normalized_ET'],label=str(year),color=color,lw=2)\n",
    "        area=np.abs(np.trapz(avg_data['Normalized_ET'],avg_data['Normalized_GPP']))\n",
    "        areas[season][year]=area\n",
    "    ax.set_title(season)\n",
    "    ax.set_xlabel('Normalized GPP',fontsize=16)\n",
    "    ax.set_ylabel('Normalized ET',fontsize=16)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylim(0,1)\n",
    "    ax.tick_params(axis='both',which='major',labelsize=14)\n",
    "    ax.legend(title='Year',fontsize=14)\n",
    "plt.tight_layout(rect=[0,0,1,0.95])\n",
    "plt.show()\n",
    "for season in areas:\n",
    "    for year in areas[season]:\n",
    "        print(f\"Area for {season} season, {year} year: {areas[season][year]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 8))\n",
    "fig.suptitle('ET vs GPP DT (Drought vs Baseline)', fontsize=20)\n",
    "areas = {}\n",
    "for i, (season_name, months) in enumerate(seasons.items()):\n",
    "    ax = axes[i]\n",
    "    season_data = merged_data[merged_data['Month'].isin(months)]\n",
    "    drought_data = season_data[season_data['Year'] == drought_year]\n",
    "    baseline_data = season_data\n",
    "    baseline_mean = baseline_data.groupby(['Hour', 'Minute']).mean().reset_index()\n",
    "    for col in ['Average_GPP_DT', 'Average_ET']:\n",
    "        Q1 = baseline_mean[col].quantile(0.25)\n",
    "        Q3 = baseline_mean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        baseline_mean = baseline_mean[(baseline_mean[col] >= lower_bound) & (baseline_mean[col] <= upper_bound)]\n",
    "    drought_data = drought_data.sort_values(by=['Hour', 'Minute'])\n",
    "    drought_mean = drought_data.groupby(['Hour', 'Minute']).mean().reset_index()\n",
    "    ax.plot(baseline_mean['Average_ET'], baseline_mean['Average_GPP_DT'], label='Baseline', color='blue', lw=2)\n",
    "    ax.plot(drought_mean['Average_ET'], drought_mean['Average_GPP_DT'], label='Drought Year', color='red', lw=2)\n",
    "    baseline_area = np.abs(np.trapz(baseline_mean['Average_GPP_DT'], baseline_mean['Average_ET']))\n",
    "    drought_area = np.abs(np.trapz(drought_mean['Average_GPP_DT'], drought_mean['Average_ET']))\n",
    "    areas[season_name] = {'Baseline': baseline_area, 'Drought': drought_area}\n",
    "    ax.set_title(season_name, fontsize=16)\n",
    "    ax.set_xlabel(\"Average ET\", fontsize=14)\n",
    "    ax.set_ylabel(\"Average GPP\", fontsize=14)\n",
    "    ax.legend(fontsize=12)\n",
    "    ax.text(0.05, 0.95, f\"Baseline Area: {baseline_area:.2f}\\nDrought Area: {drought_area:.2f}\", transform=ax.transAxes, fontsize=12, verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "for season, values in areas.items():\n",
    "    print(f\"Season: {season}\")\n",
    "    for condition, area in values.items():\n",
    "        print(f\"  {condition} Area: {area:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 16))\n",
    "fig.suptitle('Rising and Falling Curves for GPP DT vs ET (Drought vs Baseline)', fontsize=20)\n",
    "hysteresis_indices = []\n",
    "for i, (season_name, months) in enumerate(seasons.items()):\n",
    "    ax_baseline = axes[0, i]\n",
    "    ax_drought = axes[1, i]\n",
    "    season_data = merged_data[merged_data['Month'].isin(months)]\n",
    "    drought_data = season_data[season_data['Year'] == drought_year]\n",
    "    baseline_data = season_data[season_data['Year'] != drought_year]\n",
    "    baseline_mean = baseline_data.groupby(['Hour', 'Minute']).mean().reset_index()\n",
    "    for col in ['Average_GPP_DT', 'Average_ET']:\n",
    "        Q1 = baseline_mean[col].quantile(0.25)\n",
    "        Q3 = baseline_mean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        baseline_mean = baseline_mean[(baseline_mean[col] >= lower_bound) & (baseline_mean[col] <= upper_bound)]\n",
    "    drought_data = drought_data.sort_values(by=['Hour', 'Minute'])\n",
    "    drought_mean = drought_data.groupby(['Hour', 'Minute']).mean().reset_index()\n",
    "    baseline_X = baseline_mean['Average_ET'].reset_index(drop=True)\n",
    "    baseline_Y = baseline_mean['Average_GPP_DT'].reset_index(drop=True)\n",
    "    drought_X = drought_mean['Average_ET'].reset_index(drop=True)\n",
    "    drought_Y = drought_mean['Average_GPP_DT'].reset_index(drop=True)\n",
    "    baseline_max_index = baseline_X.idxmax()\n",
    "    drought_max_index = drought_X.idxmax()\n",
    "    rising_baseline_X = baseline_X[:baseline_max_index+1]\n",
    "    falling_baseline_X = baseline_X[baseline_max_index:]\n",
    "    rising_baseline_Y = baseline_Y[:baseline_max_index+1]\n",
    "    falling_baseline_Y = baseline_Y[baseline_max_index:]\n",
    "    rising_drought_X = drought_X[:drought_max_index+1]\n",
    "    falling_drought_X = drought_X[drought_max_index:]\n",
    "    rising_drought_Y = drought_Y[:drought_max_index+1]\n",
    "    falling_drought_Y = drought_Y[drought_max_index:]\n",
    "    ax_baseline.plot(rising_baseline_X, rising_baseline_Y, label=f'Rising (Baseline)', color='green', lw=2)\n",
    "    ax_baseline.plot(falling_baseline_X, falling_baseline_Y, label=f'Falling (Baseline)', color='orange', lw=2)\n",
    "    ax_drought.plot(rising_drought_X, rising_drought_Y, label=f'Rising (Drought)', color='blue', lw=2)\n",
    "    ax_drought.plot(falling_drought_X, falling_drought_Y, label=f'Falling (Drought)', color='red', lw=2)\n",
    "    rising_baseline_area = np.abs(np.trapz(rising_baseline_Y, rising_baseline_X))\n",
    "    falling_baseline_area = np.abs(np.trapz(falling_baseline_Y, falling_baseline_X))\n",
    "    rising_drought_area = np.abs(np.trapz(rising_drought_Y, rising_drought_X))\n",
    "    falling_drought_area = np.abs(np.trapz(falling_drought_Y, falling_drought_X))\n",
    "    hysteresis_index_baseline = rising_baseline_area / falling_baseline_area\n",
    "    hysteresis_index_drought = rising_drought_area / falling_drought_area\n",
    "    hysteresis_indices.append({'Season': season_name, 'Hysteresis_Index_Baseline': hysteresis_index_baseline, 'Hysteresis_Index_Drought': hysteresis_index_drought})\n",
    "    ax_baseline.set_title(f'Baseline - {season_name}', fontsize=16)\n",
    "    ax_baseline.set_xlabel(\"Average ET\", fontsize=14)\n",
    "    ax_baseline.set_ylabel(\"Average GPP\", fontsize=14)\n",
    "    ax_baseline.legend(fontsize=12)\n",
    "    ax_drought.set_title(f'Drought - {season_name}', fontsize=16)\n",
    "    ax_drought.set_xlabel(\"Average ET\", fontsize=14)\n",
    "    ax_drought.set_ylabel(\"Average GPP\", fontsize=14)\n",
    "    ax_drought.legend(fontsize=12)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n",
    "for index in hysteresis_indices:\n",
    "    print(f\"Season: {index['Season']}, Hysteresis Index (Baseline): {index['Hysteresis_Index_Baseline']}, Hysteresis Index (Drought): {index['Hysteresis_Index_Drought']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
